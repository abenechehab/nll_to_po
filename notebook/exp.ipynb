{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26505a8f",
   "metadata": {
    "id": "26505a8f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "from nll_to_po.models.dn_policy import MLPPolicy\n",
    "from nll_to_po.training.utils import train_single_policy\n",
    "import nll_to_po.training.loss as L\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\", font_scale=1.5)\n",
    "# sns.set_palette(\"colorblind\")\n",
    "# sns.despine()\n",
    "\n",
    "import wandb as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923aaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "n_experiments = 10  # Number of repetitions\n",
    "n_updates = 200\n",
    "input_dim = 4\n",
    "output_dim = 2\n",
    "hidden_sizes = [64, 64]\n",
    "\n",
    "fixed_logstd = False\n",
    "init_dist_loc = 1.0\n",
    "init_dist_scale = 0.1\n",
    "init_dist_n_samples = 25\n",
    "rsample_for_grpo = False\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for _ in range(n_experiments):\n",
    "    policy = MLPPolicy(input_dim, output_dim, hidden_sizes, fixed_logstd)\n",
    "\n",
    "    # Generate new random data for each experiment\n",
    "    X = torch.randn(1, input_dim)\n",
    "    mean_y = 2 + torch.randn(1, output_dim) * init_dist_loc\n",
    "    y = mean_y + torch.randn(init_dist_n_samples, output_dim) * init_dist_scale\n",
    "    X = X.repeat(init_dist_n_samples, 1)  # Repeat X for each sample\n",
    "\n",
    "    # Create a DataLoader\n",
    "    train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_function = L.NLL()\n",
    "    # loss_function = L.PO(\n",
    "    #     n_generations=100,\n",
    "    #     use_rsample=False,\n",
    "    #     reward_transform=\"normalize\",  # \"normalize\", \"rbf\", \"none\"\n",
    "    #     rbf_gamma=None,\n",
    "    # )\n",
    "\n",
    "    wandb_run = wb.init(\n",
    "        project=\"mse_nll_po\",\n",
    "        name=\"NLL\",\n",
    "        config={\n",
    "            \"fixed_logstd\": fixed_logstd,\n",
    "            \"init_dist_loc\": init_dist_loc,\n",
    "            \"loss\": \"NLL\",\n",
    "            \"learning_rate\": learning_rate,\n",
    "            # \"n_generations\": 100,\n",
    "            # \"reward_transform\": \"normalize\",\n",
    "            \"init_dist_n_samples\": init_dist_n_samples,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Run comparison\n",
    "    train_single_policy(\n",
    "        policy=policy,\n",
    "        train_dataloader=train_dataloader,\n",
    "        loss_function=loss_function,\n",
    "        n_updates=n_updates,\n",
    "        learning_rate=learning_rate,\n",
    "        wandb_run=wandb_run,\n",
    "    )\n",
    "\n",
    "    wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "n_experiments = 10  # Number of repetitions\n",
    "n_updates = 200\n",
    "input_dim = 4\n",
    "output_dim = 2\n",
    "hidden_sizes = [64, 64]\n",
    "\n",
    "fixed_logstd = False\n",
    "init_dist_scale = 0.1\n",
    "rsample_for_grpo = False\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for init_dist_n_samples in [1, 25]:\n",
    "    for init_dist_loc in [1.0, 7.0]:\n",
    "        for rbf_gamma in [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 100.0]:\n",
    "            for n_gen in [1, 2, 5, 10, 25, 50, 100]:\n",
    "                for _ in range(n_experiments):\n",
    "                    policy = MLPPolicy(\n",
    "                        input_dim, output_dim, hidden_sizes, fixed_logstd\n",
    "                    )\n",
    "\n",
    "                    # Generate new random data for each experiment\n",
    "                    X = torch.randn(1, input_dim)\n",
    "                    mean_y = 2 + torch.randn(1, output_dim) * init_dist_loc\n",
    "                    y = (\n",
    "                        mean_y\n",
    "                        + torch.randn(init_dist_n_samples, output_dim) * init_dist_scale\n",
    "                    )\n",
    "                    X = X.repeat(init_dist_n_samples, 1)  # Repeat X for each sample\n",
    "\n",
    "                    # Create a DataLoader\n",
    "                    train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "                    train_dataloader = torch.utils.data.DataLoader(\n",
    "                        train_dataset, batch_size=1, shuffle=True\n",
    "                    )\n",
    "\n",
    "                    # Define the loss function\n",
    "                    # loss_function = L.NLL()\n",
    "                    loss_function = L.PO(\n",
    "                        n_generations=n_gen,\n",
    "                        use_rsample=False,\n",
    "                        reward_transform=\"rbf\",  # \"normalize\", \"rbf\", \"none\"\n",
    "                        rbf_gamma=rbf_gamma,\n",
    "                    )\n",
    "\n",
    "                    wandb_run = wb.init(\n",
    "                        project=\"ablation_po_rbf\",\n",
    "                        name=f\"PO_gamma={rbf_gamma}\",\n",
    "                        config={\n",
    "                            \"fixed_logstd\": fixed_logstd,\n",
    "                            \"init_dist_loc\": init_dist_loc,\n",
    "                            \"loss\": f\"PO_gamma={rbf_gamma}\",\n",
    "                            \"learning_rate\": learning_rate,\n",
    "                            \"n_generations\": n_gen,\n",
    "                            \"reward_transform\": \"rbf\",\n",
    "                            \"init_dist_n_samples\": init_dist_n_samples,\n",
    "                            \"rbf_gamma\": rbf_gamma,\n",
    "                        },\n",
    "                    )\n",
    "\n",
    "                    # Run comparison\n",
    "                    train_single_policy(\n",
    "                        policy=policy,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        loss_function=loss_function,\n",
    "                        n_updates=n_updates,\n",
    "                        learning_rate=learning_rate,\n",
    "                        wandb_run=wandb_run,\n",
    "                    )\n",
    "\n",
    "                    wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a98cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the RBF kernel function\n",
    "def rbf_kernel(x, gamma):\n",
    "    return np.exp(-gamma * x**2)\n",
    "\n",
    "\n",
    "# Create x values\n",
    "x = np.linspace(-3, 3, 1000)\n",
    "\n",
    "# Define different gamma values\n",
    "gamma_values = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    y_rbf = rbf_kernel(x, gamma)\n",
    "    plt.plot(x, y_rbf, label=f\"Î³ = {gamma}\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"RBF Kernel Value\")\n",
    "plt.title(\"RBF Kernel with Different Gamma Values\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc4279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "c05f6123"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nllpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
